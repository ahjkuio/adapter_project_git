================================================================================
СРАВНЕНИЕ АДАПТЕРОВ LoRA И MLP
Дата: 2025-03-15 18:40:13
================================================================================

ИНФОРМАЦИЯ ОБ АДАПТЕРАХ
--------------------------------------------------------------------------------
+---------------------+----------------+--------------+
| Параметр            | LoRA           | MLP          |
+=====================+================+==============+
| Обучаемые параметры | ~2.1М          | 4211200      |
+---------------------+----------------+--------------+
| Ранг (r)            | 4              | N/A          |
+---------------------+----------------+--------------+
| Alpha (α)           | 8              | N/A          |
+---------------------+----------------+--------------+
| Скрытый размер      | N/A            | 128          |
+---------------------+----------------+--------------+
| Количество слоев    | N/A            | 4            |
+---------------------+----------------+--------------+
| Целевые модули      | q_proj, v_proj | N/A          |
+---------------------+----------------+--------------+
| Слои для адаптации  | N/A            | 0, 6, 12, 18 |
+---------------------+----------------+--------------+
| Dropout             | 0.05           | 0.1          |
+---------------------+----------------+--------------+

СРАВНЕНИЕ НА ДАТАСЕТЕ TERRa (общие способности)
--------------------------------------------------------------------------------
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| Метрика   |   Базовая модель |   LoRA | MLP   | LoRA vs Base     | MLP vs Base   | MLP vs LoRA   |
+===========+==================+========+=======+==================+===============+===============+
| Accuracy  |           0.47   | 0.47   | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| Precision |           0.5    | 0.5    | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| Recall    |           0.235  | 0.235  | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| F1        |           0.3197 | 0.3197 | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+

СРАВНЕНИЕ НА ДАТАСЕТЕ NERUS (специализированная задача)
--------------------------------------------------------------------------------
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| Метрика   |   Базовая модель |   LoRA | MLP   | LoRA vs Base     | MLP vs Base   | MLP vs LoRA   |
+===========+==================+========+=======+==================+===============+===============+
| Precision |           0.3217 | 0.3217 | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| Recall    |           0.5565 | 0.5565 | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+
| F1        |           0.3885 | 0.3885 | Н/Д   | +0.0000 (+0.00%) | Н/Д           | Н/Д           |
+-----------+------------------+--------+-------+------------------+---------------+---------------+

ОБЩИЕ ВЫВОДЫ
--------------------------------------------------------------------------------
1. На датасете TERRa (общие способности) лучшие результаты показал метод LoRA (MLP метрики недоступны).
   - LoRA: изменение F1 +0.00% относительно базовой модели
   - MLP: метрики недоступны

2. На датасете Nerus (специализированная задача) лучшие результаты показал метод LoRA (MLP метрики недоступны).
   - LoRA: изменение F1 +0.00% относительно базовой модели
   - MLP: метрики недоступны

3. С точки зрения баланса между специализацией и сохранением общих способностей лучше справился метод LoRA (MLP метрики недоступны).
   - LoRA: общий баланс +0.00
   - MLP: метрики недоступны

РЕКОМЕНДАЦИИ:

1. Необходимо обучить и оценить MLP адаптеры для полноценного сравнения.
   - Текущий отчет содержит только метрики LoRA адаптеров.
   - После получения метрик MLP повторите сравнение.

2. Рекомендуемые дальнейшие эксперименты:
   - Провести эксперименты с различными рангами (r) и alpha для LoRA
   - Тестирование разных размеров скрытого слоя MLP адаптеров
   - Эксперименты с комбинированным подходом, использующим оба типа адаптеров